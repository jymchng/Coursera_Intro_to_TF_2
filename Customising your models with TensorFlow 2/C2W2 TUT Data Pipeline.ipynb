{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T09:26:21.096195Z",
     "start_time": "2021-03-13T09:26:11.636614Z"
    },
    "id": "6JsB_bKALwj0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KT-hyAgFLwj7"
   },
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3ueZW9CLwj8"
   },
   "source": [
    " ## Coding tutorials\n",
    " #### [1. Keras datasets](#coding_tutorial_1)\n",
    " #### [2. Dataset generators](#coding_tutorial_2)\n",
    " #### [3. Keras image data augmentation](#coding_tutorial_3)\n",
    " #### [4. The Dataset class](#coding_tutorial_4)\n",
    " #### [5. Training with Datasets](#coding_tutorial_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IF-0r_trLwj9"
   },
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## Keras datasets\n",
    "\n",
    "For a list of Keras datasets and documentation on recommended usage, see [this link](https://keras.io/datasets/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T09:26:21.729219Z",
     "start_time": "2021-03-13T09:26:21.098190Z"
    },
    "id": "WHF_JbgGLwj-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyE5HuD8LwkB"
   },
   "source": [
    "#### Load the CIFAR-100 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T09:26:26.687937Z",
     "start_time": "2021-03-13T09:26:26.633082Z"
    },
    "id": "x3Flu2zSLwkC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T10:19:25.757106Z",
     "start_time": "2021-03-13T09:27:35.048933Z"
    },
    "id": "SQUmYRQdLwkF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the CIFAR-100 dataset\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data(label_mode = 'fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T10:54:10.483099Z",
     "start_time": "2021-03-13T10:54:10.477102Z"
    },
    "id": "l75ozQVFLwkI"
   },
   "outputs": [],
   "source": [
    "# Confirm that reloading the dataset does not require a download\n",
    "\n",
    "for i in train_images, train_labels, test_images, test_labels:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1UEPzrYLwkL"
   },
   "source": [
    "#### Examine the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDYN-cq9Mc2Q"
   },
   "source": [
    "#### Import the data\n",
    "\n",
    "The additional files required for this tutorial can be downloaded from the following link:\n",
    "\n",
    "cifar100_fine_labels: https://drive.google.com/open?id=1WFW1cj8v_5z1pGvq6htQyFUPrJP-Z2v5\n",
    "\n",
    "cifar100_coarse_labels: https://drive.google.com/open?id=1Jmt7o-6sP85D7iRORk5tJqJMN3wCP12p\n",
    "\n",
    "You should store these files in Drive for use in this Colab notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiplZnP2ND6o"
   },
   "outputs": [],
   "source": [
    "# Run this cell to connect to your Drive folder\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpkIbhLTLwkM"
   },
   "outputs": [],
   "source": [
    "# Examine the shape of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T10:54:16.622533Z",
     "start_time": "2021-03-13T10:54:16.295716Z"
    },
    "id": "vY58jmf5LwkS"
   },
   "outputs": [],
   "source": [
    "# Examine one of the images and its corresponding label\n",
    "\n",
    "plt.imshow(train_images[500])\n",
    "print(train_labels[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T10:54:34.042476Z",
     "start_time": "2021-03-13T10:54:33.675745Z"
    },
    "id": "Bojn7VsfLwkV"
   },
   "outputs": [],
   "source": [
    "# Load the list of labels from a JSON file\n",
    "\n",
    "import json\n",
    "\n",
    "with open('data/cifar100_fine_labels.json', 'r') as fine_labels:\n",
    "    cifar100_fine_labels = json.load(fine_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcULe51BLwkZ"
   },
   "source": [
    "The list of labels for the CIFAR-100 dataset are available [here](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T10:54:35.870843Z",
     "start_time": "2021-03-13T10:54:35.866865Z"
    },
    "id": "KXq95zzcLwka"
   },
   "outputs": [],
   "source": [
    "# Print a few of the labels\n",
    "\n",
    "cifar100_fine_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T10:54:36.880534Z",
     "start_time": "2021-03-13T10:54:36.875550Z"
    },
    "id": "F6Oqo7xKLwkd"
   },
   "outputs": [],
   "source": [
    "# Print the corresponding label for the example above\n",
    "\n",
    "cifar100_fine_labels[41]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKQA_qggLwkh"
   },
   "source": [
    "#### Load the data using different label modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T10:54:39.374051Z",
     "start_time": "2021-03-13T10:54:39.148656Z"
    },
    "id": "UkLZ3caeLwki"
   },
   "outputs": [],
   "source": [
    "# Display a few examples from category 87 (index 86) and the list of labels\n",
    "\n",
    "examples = train_images[(train_labels.T == 86)[0]][:3]\n",
    "fig, ax = plt.subplots(1,3)\n",
    "ax[0].imshow(examples[0])\n",
    "ax[1].imshow(examples[1])\n",
    "ax[2].imshow(examples[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:05:32.189140Z",
     "start_time": "2021-03-13T11:05:30.979085Z"
    },
    "id": "qdP2x7rFLwkk"
   },
   "outputs": [],
   "source": [
    "# Reload the data using the 'coarse' label mode\n",
    "\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data(label_mode = 'coarse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:05:34.791980Z",
     "start_time": "2021-03-13T11:05:34.526663Z"
    },
    "id": "zVizCMTSLwkn"
   },
   "outputs": [],
   "source": [
    "# Display three images from the dataset with the label 6 (index 5)\n",
    "\n",
    "examples = train_images[(train_labels.T == 5)[0]][:3]\n",
    "fig, ax = plt.subplots(1,3)\n",
    "ax[0].imshow(examples[0])\n",
    "ax[1].imshow(examples[1])\n",
    "ax[2].imshow(examples[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:05:45.935194Z",
     "start_time": "2021-03-13T11:05:45.918240Z"
    },
    "id": "C_MZIWCFLwks"
   },
   "outputs": [],
   "source": [
    "# Load the list of coarse labels from a JSON file\n",
    "\n",
    "with open('data/cifar100_coarse_labels.json', 'r') as coarse_labels:\n",
    "    cifar100_coarse_labels = json.load(coarse_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:05:55.227421Z",
     "start_time": "2021-03-13T11:05:55.222435Z"
    },
    "id": "wbvYhD48Lwku",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print a few of the labels\n",
    "\n",
    "cifar100_coarse_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:07:12.016661Z",
     "start_time": "2021-03-13T11:07:12.011676Z"
    },
    "id": "2KGMaEInLwkx"
   },
   "outputs": [],
   "source": [
    "# Print the corresponding label for the example above\n",
    "\n",
    "print(cifar100_fine_labels)\n",
    "cifar100_coarse_labels[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZDJui8OLwk1"
   },
   "source": [
    "#### Load the IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:29:43.272031Z",
     "start_time": "2021-03-13T11:29:43.252086Z"
    },
    "id": "UKylrcBKLwk2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:30:22.590749Z",
     "start_time": "2021-03-13T11:30:17.423543Z"
    },
    "id": "rWNp9BGZLwk4"
   },
   "outputs": [],
   "source": [
    "# Load the IMDB dataset\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:31:33.596808Z",
     "start_time": "2021-03-13T11:31:33.591829Z"
    },
    "id": "fTHEOfQ1Lwk8"
   },
   "outputs": [],
   "source": [
    "# Print an example from the training dataset, along with its corresponding label\n",
    "\n",
    "print(train_data[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:31:37.968097Z",
     "start_time": "2021-03-13T11:31:37.958083Z"
    },
    "id": "UikjKYS5Lwk-"
   },
   "outputs": [],
   "source": [
    "# Get the lengths of the input sequences\n",
    "\n",
    "sequence_lengths = [len(seq) for seq in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:31:53.544121Z",
     "start_time": "2021-03-13T11:31:53.531155Z"
    },
    "id": "3QbK1eZOLwlB"
   },
   "outputs": [],
   "source": [
    "# Determine the maximum and minimum sequence length\n",
    "\n",
    "print(np.max(sequence_lengths))\n",
    "print(np.min(sequence_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfxdEsETLwlD"
   },
   "source": [
    "#### Using Keyword Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:32:56.132388Z",
     "start_time": "2021-03-13T11:32:51.277372Z"
    },
    "id": "V_rJ9cHDLwlE"
   },
   "outputs": [],
   "source": [
    "# Load the data ignoring the 50 most frequent words, use oov_char=2 (this is the default)\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(skip_top = 50, oov_char = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:32:58.891438Z",
     "start_time": "2021-03-13T11:32:58.883459Z"
    },
    "id": "EfrBgZWXLwlH"
   },
   "outputs": [],
   "source": [
    "# Get the lengths of the input sequences\n",
    "\n",
    "sequence_lengths = [len(seq) for seq in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:32:59.883963Z",
     "start_time": "2021-03-13T11:32:59.877002Z"
    },
    "id": "iqSdCKqxLwlJ"
   },
   "outputs": [],
   "source": [
    "# Determine the maximum and minimum sequence length\n",
    "\n",
    "print(np.max(sequence_lengths))\n",
    "print(np.min(sequence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:33:02.280326Z",
     "start_time": "2021-03-13T11:33:02.269356Z"
    },
    "id": "R9RjMJaJLwlL"
   },
   "outputs": [],
   "source": [
    "# Define functions for filtering the sequences\n",
    "\n",
    "def remove_oov_char(element):\n",
    "    ''' Filter function for removing the oov_char. '''\n",
    "    return [word for word in element if word!=2]\n",
    "\n",
    "def filter_list(lst):\n",
    "    ''' Run remove_oov_char on elements in a list. '''\n",
    "    return [remove_oov_char(element) for element in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:33:45.587351Z",
     "start_time": "2021-03-13T11:33:45.215291Z"
    },
    "id": "7eBoicx1LwlO"
   },
   "outputs": [],
   "source": [
    "# Remove the oov_char from the sequences using the filter_list function\n",
    "\n",
    "train_data = filter_list(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:33:46.019145Z",
     "start_time": "2021-03-13T11:33:46.010167Z"
    },
    "id": "YZ0myFkyLwlR"
   },
   "outputs": [],
   "source": [
    "# Get the lengths of the input sequences\n",
    "\n",
    "sequence_lengths = [len(seq) for seq in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:33:49.293502Z",
     "start_time": "2021-03-13T11:33:49.286521Z"
    },
    "id": "Qy5jFTr3LwlU"
   },
   "outputs": [],
   "source": [
    "# Determine the maximum and minimum sequence length\n",
    "\n",
    "print(np.max(sequence_lengths))\n",
    "print(np.min(sequence_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43w36xfNLwlW"
   },
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Dataset generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:34:30.271135Z",
     "start_time": "2021-03-13T11:34:30.266179Z"
    },
    "id": "_GVjAo5nLwlX"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeksQNB9LwlZ"
   },
   "source": [
    "#### Load the UCI Fertility Dataset\n",
    "\n",
    "We will be using a dataset available at https://archive.ics.uci.edu/ml/datasets/Fertility from UC Irvine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDMv0Yc6NGd9"
   },
   "source": [
    "#### Import the data\n",
    "\n",
    "The dataset required for this tutorial can be downloaded from the following link:\n",
    "\n",
    "https://drive.google.com/open?id=1OA0lwa5YLDs1njS377jbqPpMSlH5TzQV\n",
    "\n",
    "You should store this file in Drive for use in this Colab notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UK-HCBxlNGpb"
   },
   "outputs": [],
   "source": [
    "# Run this cell to connect to your Drive folder\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:34:43.544375Z",
     "start_time": "2021-03-13T11:34:43.345868Z"
    },
    "id": "XKfmk3zpLwla"
   },
   "outputs": [],
   "source": [
    "# Load the fertility dataset\n",
    "\n",
    "headers = ['Season', 'Age', 'Diseases', 'Trauma', 'Surgery', 'Fever', 'Alcohol', 'Smoking', 'Sitting', 'Output']\n",
    "fertility = pd.read_csv('data/fertility_diagnosis.txt', delimiter=',', header=None, names=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:34:48.651023Z",
     "start_time": "2021-03-13T11:34:48.646014Z"
    },
    "id": "WWOyjhCJLwld"
   },
   "outputs": [],
   "source": [
    "# Print the shape of the DataFrame\n",
    "\n",
    "fertility.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:34:53.266582Z",
     "start_time": "2021-03-13T11:34:53.233607Z"
    },
    "id": "mwGWKnbbLwlf"
   },
   "outputs": [],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "fertility.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slDi0LNSLwlk"
   },
   "source": [
    "#### Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:35:09.027453Z",
     "start_time": "2021-03-13T11:35:09.016484Z"
    },
    "id": "bCmzD-5HLwll"
   },
   "outputs": [],
   "source": [
    "# Map the 'Output' feature from 'N' to 0 and from 'O' to 1\n",
    "\n",
    "fertility['Output'] = fertility['Output'].map(lambda x : 0.0 if x=='N' else 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:35:10.195679Z",
     "start_time": "2021-03-13T11:35:10.176691Z"
    },
    "id": "7yjVX1KMLwlo"
   },
   "outputs": [],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "fertility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:35:19.919645Z",
     "start_time": "2021-03-13T11:35:19.909681Z"
    },
    "id": "hJ5qjO5ALwlq"
   },
   "outputs": [],
   "source": [
    "# Convert the DataFrame so that the features are mapped to floats\n",
    "\n",
    "fertility = fertility.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:35:25.301541Z",
     "start_time": "2021-03-13T11:35:25.293565Z"
    },
    "id": "WWIZ-en6Lwls"
   },
   "outputs": [],
   "source": [
    "# Shuffle the DataFrame\n",
    "\n",
    "fertility = fertility.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:35:26.472913Z",
     "start_time": "2021-03-13T11:35:26.456956Z"
    },
    "id": "4HH_ObWqLwlu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "fertility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:35:43.161903Z",
     "start_time": "2021-03-13T11:35:43.143954Z"
    },
    "id": "oREiQC5wLwly"
   },
   "outputs": [],
   "source": [
    "# Convert the field Season to a one-hot encoded vector\n",
    "\n",
    "fertility = pd.get_dummies(fertility, prefix='Season', columns=['Season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:35:43.941279Z",
     "start_time": "2021-03-13T11:35:43.926321Z"
    },
    "id": "fDCUdq3VLwl2"
   },
   "outputs": [],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "fertility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:35:54.086618Z",
     "start_time": "2021-03-13T11:35:54.081632Z"
    },
    "id": "eukmHFMILwl5"
   },
   "outputs": [],
   "source": [
    "# Move the Output column such that it is the last column in the DataFrame\n",
    "\n",
    "fertility.columns = [col for col in fertility.columns if col != 'Output'] + ['Output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:35:55.227119Z",
     "start_time": "2021-03-13T11:35:55.210165Z"
    },
    "id": "i-anaeBLLwmB"
   },
   "outputs": [],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "fertility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:36:12.533466Z",
     "start_time": "2021-03-13T11:36:12.513521Z"
    },
    "id": "OEyYKSueLwmD"
   },
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a numpy array.\n",
    "\n",
    "fertility = fertility.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:36:20.416096Z",
     "start_time": "2021-03-13T11:36:20.409114Z"
    }
   },
   "outputs": [],
   "source": [
    "fertility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tPbAdRYLwmH"
   },
   "source": [
    "#### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:36:22.367757Z",
     "start_time": "2021-03-13T11:36:22.363769Z"
    },
    "id": "o1qYU7lcLwmI"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation set\n",
    "\n",
    "training = fertility[0:70]\n",
    "validation = fertility[70:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:36:31.831013Z",
     "start_time": "2021-03-13T11:36:31.828021Z"
    },
    "id": "XnwFqRrLLwmL"
   },
   "outputs": [],
   "source": [
    "# Verify the shape of the training data\n",
    "\n",
    "print(training.shape, validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:11:50.890254Z",
     "start_time": "2021-03-13T12:11:50.884273Z"
    },
    "id": "JvCdYLU5LwmN"
   },
   "outputs": [],
   "source": [
    "# Separate the features and labels for the validation and training data\n",
    "\n",
    "training_features = training[:,0:-1]\n",
    "training_labels = training[:,-1]\n",
    "validation_features = validation[:,0:-1]\n",
    "validation_labels = validation[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLOK8GMOLwmP"
   },
   "source": [
    "#### Create the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:01:31.246848Z",
     "start_time": "2021-03-13T12:01:31.240863Z"
    },
    "id": "uINAoFn5LwmQ"
   },
   "outputs": [],
   "source": [
    "# Create a function that returns a generator producing inputs and labels\n",
    "\n",
    "def get_generator(features, labels, batch_size=1):\n",
    "        for n in range(int(len(features)/batch_size)):\n",
    "            yield (features[n*batch_size: (n+1)*batch_size], labels[n*batch_size: (n+1)*batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:01:31.923403Z",
     "start_time": "2021-03-13T12:01:31.919414Z"
    },
    "id": "W_zKx3oJLwmS"
   },
   "outputs": [],
   "source": [
    "# Apply the function to our training features and labels with a batch size of 10\n",
    "\n",
    "train_generator = get_generator(training_features, training_labels, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:01:32.783948Z",
     "start_time": "2021-03-13T12:01:32.776968Z"
    },
    "id": "7Y3jCTRuLwmT"
   },
   "outputs": [],
   "source": [
    "# Test the generator using the next() function\n",
    "\n",
    "next(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KA-VnvRpLwmW"
   },
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:14:08.875064Z",
     "start_time": "2021-03-13T12:14:08.763363Z"
    },
    "id": "I5T3dXGZLwmW"
   },
   "outputs": [],
   "source": [
    "# Create a model using Keras with 3 layers\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization\n",
    "\n",
    "input_shape = (12,)\n",
    "output_shape = (1,)\n",
    "\n",
    "model_input = Input(input_shape)\n",
    "batch_1 = BatchNormalization(momentum=0.8)(model_input)\n",
    "dense_1 = Dense(100, activation='relu')(batch_1)\n",
    "batch_2 = BatchNormalization(momentum=0.8)(dense_1)\n",
    "output = Dense(1, activation='sigmoid', kernel_regularizer = 'l1')(batch_2)\n",
    "\n",
    "model = Model([model_input], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:14:09.696442Z",
     "start_time": "2021-03-13T12:14:09.690458Z"
    },
    "id": "xCBoGMMULwmY"
   },
   "outputs": [],
   "source": [
    "# Display the model summary to show the resultant structure\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-djfT1vDLwma"
   },
   "source": [
    "#### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:14:14.870365Z",
     "start_time": "2021-03-13T12:14:14.866376Z"
    },
    "id": "D_PyDixLLwma"
   },
   "outputs": [],
   "source": [
    "# Create the optimizer object\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:14:15.580925Z",
     "start_time": "2021-03-13T12:14:15.528069Z"
    },
    "id": "IZUjV3LpLwmc"
   },
   "outputs": [],
   "source": [
    "# Compile the model with loss function and metric\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxB-r6_sLwmd"
   },
   "source": [
    "#### Train and evaluate the model using the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:14:20.676554Z",
     "start_time": "2021-03-13T12:14:20.672563Z"
    },
    "id": "zCmNFC0eLwmd"
   },
   "outputs": [],
   "source": [
    "# Calculate the number of training steps per epoch for the given batch size.\n",
    "\n",
    "batch_size = 5\n",
    "train_steps = len(training) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:14:21.357733Z",
     "start_time": "2021-03-13T12:14:21.354741Z"
    },
    "id": "tCyaX46bLwmf"
   },
   "outputs": [],
   "source": [
    "# Set the epochs to 3\n",
    "\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:14:23.435404Z",
     "start_time": "2021-03-13T12:14:22.707311Z"
    },
    "id": "9TKc7muJLwmg"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "\"\"\"\n",
    "training_features = training[:,0:-1]\n",
    "training_labels = training[:,-1]\n",
    "validation_features = validation[:,0:-1]\n",
    "validation_labels = validation[:,-1]\n",
    "\"\"\"\n",
    "for epoch in range(epochs):\n",
    "    train_generator = get_generator(training_features, training_labels, batch_size=batch_size)\n",
    "    validation_generator = get_generator(validation_features, validation_labels, batch_size=batch_size)\n",
    "    model.fit_generator(train_generator, steps_per_epoch=train_steps, validation_data = validation_generator, validation_steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:14:35.118207Z",
     "start_time": "2021-03-13T12:14:35.098266Z"
    },
    "id": "5-6hh7BsLwmj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try to run the fit_generator function once more; observe what happens\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:36:04.365630Z",
     "start_time": "2021-03-13T12:36:04.358648Z"
    }
   },
   "outputs": [],
   "source": [
    "model.layers[-1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eASEXb7uLwml"
   },
   "source": [
    "#### Make an infinitely looping generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:06:55.577052Z",
     "start_time": "2021-03-13T12:06:55.571073Z"
    },
    "id": "oX2TZzl2Lwmm"
   },
   "outputs": [],
   "source": [
    "# Create a function that returns an infinitely looping generator\n",
    "\n",
    "def get_generator_cyclic(features, labels, batch_size=1):\n",
    "    # Add in while True to make it cyclic, infinitely generating\n",
    "    while True:\n",
    "        for n in range(int(len(features)/batch_size)):\n",
    "            yield (features[n*batch_size: (n+1)*batch_size], labels[n*batch_size: (n+1)*batch_size])\n",
    "    # After yielding, the generator will permute the data\n",
    "    permuted = np.random.permutation(len(features))\n",
    "    features = features[permuted]\n",
    "    labels = labels[permuted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:06:56.247321Z",
     "start_time": "2021-03-13T12:06:56.243290Z"
    },
    "id": "WkZIx02TLwmo"
   },
   "outputs": [],
   "source": [
    "# Create a generator using this function.\n",
    "\n",
    "train_generator_cyclic = get_generator_cyclic(training_features, training_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:06:57.267237Z",
     "start_time": "2021-03-13T12:06:57.263248Z"
    },
    "id": "rCXB7YBZLwmr"
   },
   "outputs": [],
   "source": [
    "# Assert that the new cyclic generator does not raise a StopIteration\n",
    "\n",
    "for i in range(2*train_steps):\n",
    "    next(train_generator_cyclic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:07:19.358397Z",
     "start_time": "2021-03-13T12:07:19.353410Z"
    },
    "id": "FJXeBNFALwms"
   },
   "outputs": [],
   "source": [
    "# Generate a cyclic validation generator\n",
    "\n",
    "validation_generator_cyclic = get_generator_cyclic(validation_features, validation_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:08:45.901414Z",
     "start_time": "2021-03-13T12:08:41.260085Z"
    },
    "id": "-ezRy60iLwmu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "model.fit_generator(train_generator_cyclic, steps_per_epoch=train_steps, validation_data = validation_generator_cyclic,\n",
    "                    validation_steps = 1, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CndbEe9-Lwmw"
   },
   "source": [
    "#### Evaluate the model and get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:11:19.137771Z",
     "start_time": "2021-03-13T12:11:19.133780Z"
    },
    "id": "CAPuIgstLwmw"
   },
   "outputs": [],
   "source": [
    "# Let's obtain a validation data generator.\n",
    "\n",
    "validation_generator = get_generator(validation_features, validation_labels, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:11:19.854874Z",
     "start_time": "2021-03-13T12:11:19.843896Z"
    },
    "id": "xs38y9RaLwmz"
   },
   "outputs": [],
   "source": [
    "# Get predictions on the validation data\n",
    "\n",
    "predictions = model.predict_generator(validation_generator, steps = 1)\n",
    "print(np.round(predictions.T[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:11:56.111043Z",
     "start_time": "2021-03-13T12:11:56.107034Z"
    },
    "id": "4Ce17XxwLwm4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the corresponding validation labels\n",
    "\n",
    "print(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:12:00.708511Z",
     "start_time": "2021-03-13T12:12:00.705521Z"
    },
    "id": "nUUeWVS1Lwm6"
   },
   "outputs": [],
   "source": [
    "# Obtain a validation data generator\n",
    "\n",
    "validation_generator = get_generator(validation_features, validation_labels, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:12:25.803557Z",
     "start_time": "2021-03-13T12:12:25.787600Z"
    },
    "id": "shBJD8w4Lwm7"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "evaluations = model.evaluate_generator(validation_generator, steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:12:33.080187Z",
     "start_time": "2021-03-13T12:12:33.070216Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgEaDU0TLwm8"
   },
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## Keras image data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fea1o5zdlS0p"
   },
   "source": [
    "#### Import the data\n",
    "\n",
    "The dataset required for this tutorial can be downloaded from the following link:\n",
    "\n",
    "https://drive.google.com/open?id=11Y43ta5gT672L3sfJFR2DvPs-ralY5Pd\n",
    "\n",
    "You should store these files in Drive for use in this Colab notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPDIjLB8lW6v"
   },
   "outputs": [],
   "source": [
    "# Run this cell to connect to your Drive folder\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:36:33.726212Z",
     "start_time": "2021-03-13T12:36:33.721227Z"
    },
    "id": "jdw6c9W-Lwm8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PTkNo-uLwm-"
   },
   "source": [
    "#### Load the CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:36:34.891490Z",
     "start_time": "2021-03-13T12:36:34.888482Z"
    },
    "id": "-174tvQULwm-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:28:45.396890Z",
     "start_time": "2021-03-13T12:36:35.818106Z"
    },
    "id": "P_ipqjVnLwnA"
   },
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "\n",
    "(training_features, training_labels), (test_features, test_labels) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:41:37.899406Z",
     "start_time": "2021-03-13T13:41:37.887439Z"
    },
    "id": "JH-q30M2LwnC"
   },
   "outputs": [],
   "source": [
    "# Convert the labels to a one-hot encoding\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "training_labels = tf.keras.utils.to_categorical(training_labels, num_classes)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyi9F1cRLwnF"
   },
   "source": [
    "#### Create a generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:41:42.742566Z",
     "start_time": "2021-03-13T13:41:42.737580Z"
    },
    "id": "RiTmYP9HLwnF"
   },
   "outputs": [],
   "source": [
    "# Create a function that returns a data generator\n",
    "\n",
    "def get_generator(features, labels, batch_size=1):\n",
    "    for n in range(int(len(features)/batch_size)):\n",
    "        yield (features[n*batch_size:(n+1)*batch_size], labels[n*batch_size:(n+1)*batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:41:43.482292Z",
     "start_time": "2021-03-13T13:41:43.478237Z"
    },
    "id": "aXXF9JKNLwnI"
   },
   "outputs": [],
   "source": [
    "# Use the function we created to get a training data generator with a batch size of 1\n",
    "\n",
    "training_generator = get_generator(training_features, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:41:44.530220Z",
     "start_time": "2021-03-13T13:41:44.525234Z"
    },
    "id": "ZaflrvQYLwnL"
   },
   "outputs": [],
   "source": [
    "# Assess the shape of the items generated by training_generator using the `next` function to yield an item.\n",
    "\n",
    "image, label = next(training_generator)\n",
    "print(image.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:41:47.096099Z",
     "start_time": "2021-03-13T13:41:46.950515Z"
    },
    "id": "VXS3YwfdLwnQ"
   },
   "outputs": [],
   "source": [
    "# Test the training generator by obtaining an image using the `next` generator function, and then using imshow to plot it.\n",
    "# Print the corresponding label\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "image, label = next(training_generator)\n",
    "image_unbatched = image[0,:,:,:]\n",
    "imshow(image_unbatched)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:41:52.323114Z",
     "start_time": "2021-03-13T13:41:52.319152Z"
    },
    "id": "IRHQU5fyLwnS"
   },
   "outputs": [],
   "source": [
    "# Reset the generator by re-running the `get_generator` function.\n",
    "\n",
    "train_generator = get_generator(training_features, training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUfxD0WHLwnU"
   },
   "source": [
    "#### Create a data augmention generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:41:53.456313Z",
     "start_time": "2021-03-13T13:41:53.438359Z"
    },
    "id": "S209JxdNLwnU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:41:54.289852Z",
     "start_time": "2021-03-13T13:41:54.284866Z"
    },
    "id": "R80OSZxoLwnX"
   },
   "outputs": [],
   "source": [
    "# Create a function to convert an image to monochrome\n",
    "\n",
    "def monochrome(x):\n",
    "    def func_bw(a):\n",
    "        average_colour = np.mean(a)\n",
    "        return [average_colour, average_colour, average_colour]\n",
    "    x = np.apply_along_axis(func_bw, -1, x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:56:11.121150Z",
     "start_time": "2021-03-13T13:56:10.279403Z"
    },
    "id": "3B_-LrD8LwnZ"
   },
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator object\n",
    "\n",
    "image_generator = ImageDataGenerator(preprocessing_function = monochrome, # Preprocessing function\n",
    "                                    rotation_range=180,\n",
    "                                    rescale = (1/255.0))\n",
    "\n",
    "image_generator.fit(training_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wheasgOSLwna"
   },
   "source": [
    "Check [the documentation](https://keras.io/preprocessing/image/) for the full list of image data augmentation options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:57:24.554284Z",
     "start_time": "2021-03-13T13:57:24.229121Z"
    },
    "id": "ElwkY6hzLwna"
   },
   "outputs": [],
   "source": [
    "# Create an iterable generator using the `flow` function\n",
    "\n",
    "image_generator_iterable = image_generator.flow(training_features, training_labels, shuffle = False, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:57:31.454641Z",
     "start_time": "2021-03-13T13:57:31.222947Z"
    },
    "id": "G_MojVrRLwnc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show a sample from the generator and compare with the original\n",
    "\n",
    "image, label = next(image_generator_iterable)\n",
    "image_orig, label_orig = next(train_generator)\n",
    "figs, axes = plt.subplots(1,2)\n",
    "axes[0].imshow(image[0,:,:,:])\n",
    "axes[0].set_title('Transformed')\n",
    "axes[1].imshow(image_orig[0,:,:,:])\n",
    "axes[1].set_title('Original')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lDJvPvfLwnd"
   },
   "source": [
    "#### Flow from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:58:26.734248Z",
     "start_time": "2021-03-13T13:58:26.730260Z"
    },
    "id": "l0sOke4dLwne"
   },
   "outputs": [],
   "source": [
    "# Inspect the directory structure\n",
    "\n",
    "train_path = 'data/flowers-recognition-split/train'\n",
    "val_path = 'data/flowers-recognition-split/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:58:27.524467Z",
     "start_time": "2021-03-13T13:58:27.520476Z"
    },
    "id": "nU_0lGLnLwnf"
   },
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator object\n",
    "\n",
    "datagenerator = ImageDataGenerator(rescale=(1/255.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T13:58:28.109340Z",
     "start_time": "2021-03-13T13:58:28.100357Z"
    },
    "id": "rNSTFnZpLwng"
   },
   "outputs": [],
   "source": [
    "classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T14:01:49.117647Z",
     "start_time": "2021-03-13T14:01:48.896275Z"
    },
    "id": "DoSrRM2vLwni"
   },
   "outputs": [],
   "source": [
    "# Create a training data generator\n",
    "\n",
    "# Classes Parameter:\n",
    "# Optional list of class subdirectories\n",
    "# (e.g. `['dogs', 'cats']`). Default: None.\n",
    "# If not provided, the list of classes will be automatically\n",
    "# inferred from the subdirectory names/structure\n",
    "# under `directory`, where each subdirectory will\n",
    "# be treated as a different class\n",
    "\n",
    "train_generator = datagenerator.flow_from_directory(train_path, # Specify where to take the images from\n",
    "                                                   batch_size = 64, # Put them into batches\n",
    "                                                   classes = classes, # Identify their classes\n",
    "                                                   target_size = (16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T14:02:25.832615Z",
     "start_time": "2021-03-13T14:02:25.713982Z"
    },
    "id": "I4iABrtkLwnj"
   },
   "outputs": [],
   "source": [
    "# Create a validation data generator\n",
    "\n",
    "val_generator = datagenerator.flow_from_directory(val_path, # Specify where to take the images from\n",
    "                                                   batch_size = 64, # Put them into batches\n",
    "                                                   classes = classes, # Identify their classes\n",
    "                                                   target_size = (16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T14:02:29.129986Z",
     "start_time": "2021-03-13T14:02:26.474835Z"
    },
    "id": "xttbpzhiLwnn"
   },
   "outputs": [],
   "source": [
    "# Get and display an image and label from the training generator\n",
    "\n",
    "x = next(train_generator)\n",
    "imshow(x[0][4])\n",
    "print(x[1][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T14:02:57.287109Z",
     "start_time": "2021-03-13T14:02:57.049994Z"
    },
    "id": "eubMyZu7Lwnu"
   },
   "outputs": [],
   "source": [
    "# Reset the training generator\n",
    "\n",
    "train_generator = datagenerator.flow_from_directory(train_path, # Specify where to take the images from\n",
    "                                                   batch_size = 64, # Put them into batches\n",
    "                                                   classes = classes, # Identify their classes\n",
    "                                                   target_size = (16,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuICkLdgLwnv"
   },
   "source": [
    "#### Create a model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T14:03:00.647770Z",
     "start_time": "2021-03-13T14:03:00.541057Z"
    },
    "id": "Vli6KboxLwnv",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build a CNN model\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Flatten, Dense\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Input((16,16,3)))\n",
    "model.add(Conv2D(8, (8, 8), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((4,4)))\n",
    "model.add(Conv2D(8, (8, 8), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(4, (4, 4), padding='same', activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T14:03:01.351607Z",
     "start_time": "2021-03-13T14:03:01.347610Z"
    },
    "id": "1EpyPWDtLwnw"
   },
   "outputs": [],
   "source": [
    "# Create an optimizer object\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T14:03:01.998086Z",
     "start_time": "2021-03-13T14:03:01.955146Z"
    },
    "id": "KkzxS4w8Lwny"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRFuAO0dLwnz"
   },
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdlrTTxkLwn1"
   },
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T14:03:03.873953Z",
     "start_time": "2021-03-13T14:03:03.869963Z"
    },
    "id": "8cXhw2VhLwn1"
   },
   "outputs": [],
   "source": [
    "# Calculate the training generator and test generator steps per epoch\n",
    "\n",
    "train_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
    "val_steps = val_generator.n // val_generator.batch_size\n",
    "print(train_steps_per_epoch, val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T14:05:55.503654Z",
     "start_time": "2021-03-13T14:04:44.112972Z"
    },
    "id": "Q3daJBkILwn4"
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                   steps_per_epoch = train_steps_per_epoch,\n",
    "                   epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoxWasQKLwn5"
   },
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T14:07:11.509023Z",
     "start_time": "2021-03-13T14:06:58.528006Z"
    },
    "id": "-85jqQXiLwn6"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "# steps: Total number of steps (batches of samples)\n",
    "#         to yield from `generator` before stopping.\n",
    "\n",
    "model.evaluate_generator(val_generator, # Evaluate => Validation\n",
    "                        steps = val_steps \n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zS5yD7TaLwn7"
   },
   "source": [
    "#### Predict using the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T14:08:19.683729Z",
     "start_time": "2021-03-13T14:08:19.498226Z"
    },
    "id": "Rz3CsLtgLwn8"
   },
   "outputs": [],
   "source": [
    "# Predict labels with the model\n",
    "\n",
    "predictions = model.predict_generator(val_generator,\n",
    "                                     steps = 1)\n",
    "print(np.argmax(np.round(predictions, 2), axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JW1KSTrfLwn_"
   },
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## The Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB1fIrr8lmUb"
   },
   "source": [
    "#### Import the data\n",
    "\n",
    "The dataset required for this tutorial can be downloaded from the following link:\n",
    "\n",
    "https://drive.google.com/open?id=1BAjGPFlpqsDdWof50Ng3Fmju5O8F1_uZ\n",
    "\n",
    "You should store these files in Drive for use in this Colab notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfnXkSB3lmek"
   },
   "outputs": [],
   "source": [
    "# Run this cell to connect to your Drive folder\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T12:20:29.239786Z",
     "start_time": "2021-03-14T12:20:20.749233Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T12:20:08.932829Z",
     "start_time": "2021-03-14T12:20:06.463197Z"
    },
    "id": "_xONz3oFLwn_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqqV3Ox9LwoA"
   },
   "source": [
    "#### Create a simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:30:56.803958Z",
     "start_time": "2021-03-14T13:30:56.800954Z"
    },
    "id": "p7i5Nkm6LwoA"
   },
   "outputs": [],
   "source": [
    "x = np.zeros((100,10,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:31:14.248389Z",
     "start_time": "2021-03-14T13:31:14.145609Z"
    },
    "id": "VRIbPGW0LwoC"
   },
   "outputs": [],
   "source": [
    "# Create a dataset from the tensor x\n",
    "\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices(x) # from_tensor_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:31:47.282866Z",
     "start_time": "2021-03-14T13:31:47.277883Z"
    },
    "id": "CPIBuRAPLwoE"
   },
   "outputs": [],
   "source": [
    "# Inspect the Dataset object\n",
    "\n",
    "dataset1.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:32:29.667521Z",
     "start_time": "2021-03-14T13:32:29.663532Z"
    },
    "id": "cwXTdMGYLwoF"
   },
   "outputs": [],
   "source": [
    "x2 = [np.zeros((10,2,2)), np.zeros((5,2,2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:32:43.321406Z",
     "start_time": "2021-03-14T13:32:43.264560Z"
    },
    "id": "u33v-mOtLwoG"
   },
   "outputs": [],
   "source": [
    "# Try creating a dataset from the tensor x2\n",
    "\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:35:44.635615Z",
     "start_time": "2021-03-14T13:35:44.631627Z"
    },
    "id": "VlwcxydiLwoH"
   },
   "outputs": [],
   "source": [
    "x2 = [np.zeros((10,1)), np.zeros((10,1)), np.zeros((10,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:35:52.122607Z",
     "start_time": "2021-03-14T13:35:52.117620Z"
    },
    "id": "MWA_WwA9LwoI"
   },
   "outputs": [],
   "source": [
    "# Create another dataset from the new x2 and inspect the Dataset object\n",
    "\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:35:52.803996Z",
     "start_time": "2021-03-14T13:35:52.797015Z"
    },
    "id": "RaAx8T-8LwoK"
   },
   "outputs": [],
   "source": [
    "# Print the element_spec\n",
    "\n",
    "print(dataset2.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d8X74-yLwoL"
   },
   "source": [
    "#### Create a zipped dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:37:24.148030Z",
     "start_time": "2021-03-14T13:37:24.141080Z"
    },
    "id": "pll2VDVALwoM"
   },
   "outputs": [],
   "source": [
    "# Combine the two datasets into one larger dataset\n",
    "\n",
    "dataset_zipped = tf.data.Dataset.zip((dataset1, dataset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:37:24.663651Z",
     "start_time": "2021-03-14T13:37:24.657669Z"
    },
    "id": "YFMyovAFLwoO"
   },
   "outputs": [],
   "source": [
    "# Print the element_spec\n",
    "\n",
    "print(dataset_zipped.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:37:29.331921Z",
     "start_time": "2021-03-14T13:37:29.328928Z"
    },
    "id": "AKlzGVR-LwoQ"
   },
   "outputs": [],
   "source": [
    "# Define a function to find the number of batches in a dataset\n",
    "\n",
    "def get_batches(dataset):\n",
    "    iter_dataset = iter(dataset)\n",
    "    i = 0\n",
    "    try:\n",
    "        while next(iter_dataset):\n",
    "            i = i+1\n",
    "    except:\n",
    "        return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:37:30.016876Z",
     "start_time": "2021-03-14T13:37:29.916090Z"
    },
    "id": "7pN5h3VbLwoS"
   },
   "outputs": [],
   "source": [
    "# Find the number of batches in the zipped Dataset\n",
    "\n",
    "get_batches(dataset_zipped)\n",
    "\n",
    "# The larger dataset will be trimmed to accomodate the smaller dataset size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agL_w4bhLwoU"
   },
   "source": [
    "#### Create a dataset from numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:38:44.304190Z",
     "start_time": "2021-03-14T13:38:43.997014Z"
    },
    "id": "u8BG27uVLwoU"
   },
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "\n",
    "(train_features, train_labels), (test_features, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(type(train_features), type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:40:06.272301Z",
     "start_time": "2021-03-14T13:40:06.268312Z"
    },
    "id": "n9z_XKC5LwoX"
   },
   "outputs": [],
   "source": [
    "# Create a Dataset from the MNIST data\n",
    "\n",
    "mnist_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels) # Pass in a tuple as arg\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:40:07.356999Z",
     "start_time": "2021-03-14T13:40:07.353009Z"
    },
    "id": "X2huRDyELwob"
   },
   "outputs": [],
   "source": [
    "# Inspect the Dataset object\n",
    "\n",
    "print(mnist_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:41:45.228266Z",
     "start_time": "2021-03-14T13:41:45.143456Z"
    },
    "id": "fYy7jUxxLwog"
   },
   "outputs": [],
   "source": [
    "# Inspect the length of an element using the take method\n",
    "\n",
    "print(mnist_dataset.take(1))\n",
    "print(iter(mnist_dataset.take(1)))\n",
    "print(next(iter(mnist_dataset.take(1))))\n",
    "element = next(iter(mnist_dataset.take(1)))\n",
    "print(len(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:42:26.858587Z",
     "start_time": "2021-03-14T13:42:26.854595Z"
    },
    "id": "vmU3DT_0Lwok"
   },
   "outputs": [],
   "source": [
    "# Examine the shapes of the data\n",
    "\n",
    "print(element[0].shape)\n",
    "print(element[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgdUwwomLwom"
   },
   "source": [
    "#### Create a dataset from text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:42:33.770462Z",
     "start_time": "2021-03-14T13:42:33.765476Z"
    },
    "id": "zc2ox0fXLwon"
   },
   "outputs": [],
   "source": [
    "# Print the list of text files\n",
    "\n",
    "text_files = sorted([f.path for f in os.scandir('data/shakespeare')])\n",
    "\n",
    "print(text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:42:38.889963Z",
     "start_time": "2021-03-14T13:42:38.866029Z"
    },
    "id": "K91kV97kLwoo"
   },
   "outputs": [],
   "source": [
    "# Load the first file using python and print the first 5 lines.\n",
    "\n",
    "with open(text_files[0], 'r') as fil:\n",
    "    contents = [fil.readline() for i in range(5)]\n",
    "    for line in contents:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:38.913333Z",
     "start_time": "2021-03-14T13:43:38.795601Z"
    },
    "id": "5MMqVhxNLwop"
   },
   "outputs": [],
   "source": [
    "# Load the lines from the files into a dataset using TextLineDataset\n",
    "\n",
    "shakespeare_dataset = tf.data.TextLineDataset(text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:39.877293Z",
     "start_time": "2021-03-14T13:43:39.839376Z"
    },
    "id": "sEM2up5CLwoq"
   },
   "outputs": [],
   "source": [
    "# Use the take method to get and print the first 5 lines of the dataset\n",
    "\n",
    "first_5_lines_dataset = iter(shakespeare_dataset.take(5))\n",
    "lines = [line for line in first_5_lines_dataset]\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:50.170093Z",
     "start_time": "2021-03-14T13:43:50.162101Z"
    },
    "id": "t06mXu1oLwor"
   },
   "outputs": [],
   "source": [
    "# Compute the number of lines in the first file\n",
    "\n",
    "lines = []\n",
    "with open(text_files[0], 'r') as fil:\n",
    "    line = fil.readline()\n",
    "    while line:\n",
    "        lines.append(line)\n",
    "        line = fil.readline()\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:51.815046Z",
     "start_time": "2021-03-14T13:43:51.520801Z"
    },
    "id": "GS3TysHqLwot"
   },
   "outputs": [],
   "source": [
    "# Compute the number of lines in the shakespeare dataset we created\n",
    "\n",
    "shakespeare_dataset_iterator = iter(shakespeare_dataset)\n",
    "lines = [line for line in shakespeare_dataset_iterator]\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJWNhXxMLwov"
   },
   "source": [
    "#### Interleave lines from the text data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:59.411241Z",
     "start_time": "2021-03-14T13:43:59.402267Z"
    },
    "id": "n7ukqFrcLwov",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a dataset of the text file strings\n",
    "\n",
    "text_files_dataset = tf.data.Dataset.from_tensor_slices(text_files)\n",
    "files = [file for file in text_files_dataset]\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T14:02:30.464369Z",
     "start_time": "2021-03-14T14:02:30.445421Z"
    },
    "id": "UGgRFvR_Lwox"
   },
   "outputs": [],
   "source": [
    "# Interleave the lines from the text files\n",
    "\"\"\"\n",
    "cycle_length: (Optional.) The number of input elements that will be\n",
    "    processed concurrently. If not specified, the value will be derived from\n",
    "    the number of available CPU cores. If the `num_parallel_calls` argument\n",
    "    is set to `tf.data.experimental.AUTOTUNE`, the `cycle_length` argument\n",
    "    also identifies the maximum degree of parallelism.\n",
    "\"\"\"\n",
    "\n",
    "interleaved_shakespeare_dataset = text_files_dataset.interleave(tf.data.TextLineDataset, cycle_length = 9)\n",
    "interleaved_shakespeare_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T14:01:31.705921Z",
     "start_time": "2021-03-14T14:01:31.685975Z"
    },
    "id": "x88YAMsuLwoz"
   },
   "outputs": [],
   "source": [
    "# Print the first 10 elements of the interleaved dataset\n",
    "\n",
    "lines = [line for line in iter(interleaved_shakespeare_dataset.take(20))]\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Px88RXmLwo0"
   },
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## Training with Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TfCscLFLLwo1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEq4s3oHLwo3"
   },
   "source": [
    "#### Load the UCI Bank Marketing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NukSa_ESmgRg"
   },
   "source": [
    "#### Import the data\n",
    "\n",
    "The dataset required for this tutorial can be downloaded from the following link:\n",
    "\n",
    "https://drive.google.com/open?id=1cNtP4iDyGhF620ZbmJdmJWYQrRgJTCum\n",
    "\n",
    "You should store these files in Drive for use in this Colab notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TD43V9imgeD"
   },
   "outputs": [],
   "source": [
    "# Run this cell to connect to your Drive folder\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:23.088180Z",
     "start_time": "2021-03-15T02:01:19.115232Z"
    },
    "id": "8mWVTUMGLwo4"
   },
   "outputs": [],
   "source": [
    "# Load the CSV file into a pandas DataFrame\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "bank_dataframe = pd.read_csv('data/bank/bank-full.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:23.995013Z",
     "start_time": "2021-03-15T02:01:23.960107Z"
    },
    "id": "yhXvshyRLwo6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "bank_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:24.883976Z",
     "start_time": "2021-03-15T02:01:24.876997Z"
    },
    "id": "wTEQWdkfLwo9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45211, 17)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the DataFrame\n",
    "\n",
    "print(bank_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:25.668764Z",
     "start_time": "2021-03-15T02:01:25.652807Z"
    },
    "id": "M8ORhBIMLwo_"
   },
   "outputs": [],
   "source": [
    "# Select features from the DataFrame\n",
    "\n",
    "features = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
    "            'loan', 'contact', 'campaign', 'pdays', 'poutcome']\n",
    "labels = ['y']\n",
    "\n",
    "bank_dataframe = bank_dataframe.filter(features + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:26.523537Z",
     "start_time": "2021-03-15T02:01:26.510570Z"
    },
    "id": "OvhQZha0LwpA",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  campaign  pdays poutcome   y  \n",
       "0  unknown         1     -1  unknown  no  \n",
       "1  unknown         1     -1  unknown  no  \n",
       "2  unknown         1     -1  unknown  no  \n",
       "3  unknown         1     -1  unknown  no  \n",
       "4  unknown         1     -1  unknown  no  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "bank_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDGZ4VF-LwpC"
   },
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:29.612661Z",
     "start_time": "2021-03-15T02:01:27.885120Z"
    },
    "id": "l5OJBhpHLwpC"
   },
   "outputs": [],
   "source": [
    "# Convert the categorical features in the DataFrame to one-hot encodings\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "categorical_features = ['default', 'housing', 'job', 'loan', 'education', 'contact', 'poutcome']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    bank_dataframe[feature] = tuple(encoder.fit_transform(bank_dataframe[feature]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:30.284324Z",
     "start_time": "2021-03-15T02:01:30.261386Z"
    },
    "id": "_H29rfTRLwpD",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>(0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>married</td>\n",
       "      <td>(0, 0, 1, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>2143</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0)</td>\n",
       "      <td>single</td>\n",
       "      <td>(0, 1, 0, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>29</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>(0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>married</td>\n",
       "      <td>(0, 1, 0, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>2</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>(0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>married</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>1506</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1)</td>\n",
       "      <td>single</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                                   job  marital     education default  \\\n",
       "0   58  (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)  married  (0, 0, 1, 0)    (0,)   \n",
       "1   44  (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0)   single  (0, 1, 0, 0)    (0,)   \n",
       "2   33  (0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0)  married  (0, 1, 0, 0)    (0,)   \n",
       "3   47  (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)  married  (0, 0, 0, 1)    (0,)   \n",
       "4   33  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1)   single  (0, 0, 0, 1)    (0,)   \n",
       "\n",
       "   balance housing  loan    contact  campaign  pdays      poutcome   y  \n",
       "0     2143    (1,)  (0,)  (0, 0, 1)         1     -1  (0, 0, 0, 1)  no  \n",
       "1       29    (1,)  (0,)  (0, 0, 1)         1     -1  (0, 0, 0, 1)  no  \n",
       "2        2    (1,)  (1,)  (0, 0, 1)         1     -1  (0, 0, 0, 1)  no  \n",
       "3     1506    (1,)  (0,)  (0, 0, 1)         1     -1  (0, 0, 0, 1)  no  \n",
       "4        1    (0,)  (0,)  (0, 0, 1)         1     -1  (0, 0, 0, 1)  no  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "bank_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:31.069482Z",
     "start_time": "2021-03-15T02:01:30.996678Z"
    },
    "id": "HzA8Yfl7LwpE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>(0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>married</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>5</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>(0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>divorced</td>\n",
       "      <td>(0, 0, 1, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>133</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>(1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>single</td>\n",
       "      <td>(0, 1, 0, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>53</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(1, 0, 0)</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>(0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>married</td>\n",
       "      <td>(1, 0, 0, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>407</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0, 1, 0)</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>(0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>single</td>\n",
       "      <td>(1, 0, 0, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>1770</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(1, 0, 0)</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>(1, 0, 0, 0)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>44</td>\n",
       "      <td>(0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>single</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>0</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>54</td>\n",
       "      <td>(0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>married</td>\n",
       "      <td>(0, 1, 0, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>2895</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(1, 0, 0)</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>(1, 0, 0, 0)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>33</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0)</td>\n",
       "      <td>single</td>\n",
       "      <td>(0, 1, 0, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>-32</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(1, 0, 0)</td>\n",
       "      <td>12</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>41</td>\n",
       "      <td>(0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>married</td>\n",
       "      <td>(0, 1, 0, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>114</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>31</td>\n",
       "      <td>(0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>married</td>\n",
       "      <td>(0, 0, 1, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>827</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age                                   job   marital     education  \\\n",
       "0       38  (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)   married  (0, 0, 0, 1)   \n",
       "1       36  (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)  divorced  (0, 0, 1, 0)   \n",
       "2       25  (1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)    single  (0, 1, 0, 0)   \n",
       "3       41  (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)   married  (1, 0, 0, 0)   \n",
       "4       32  (0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0)    single  (1, 0, 0, 0)   \n",
       "...    ...                                   ...       ...           ...   \n",
       "45206   44  (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)    single  (0, 0, 0, 1)   \n",
       "45207   54  (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)   married  (0, 1, 0, 0)   \n",
       "45208   33  (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0)    single  (0, 1, 0, 0)   \n",
       "45209   41  (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)   married  (0, 1, 0, 0)   \n",
       "45210   31  (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)   married  (0, 0, 1, 0)   \n",
       "\n",
       "      default  balance housing  loan    contact  campaign  pdays  \\\n",
       "0        (0,)        5    (1,)  (0,)  (0, 0, 1)         2     -1   \n",
       "1        (0,)      133    (1,)  (0,)  (0, 0, 1)         1     -1   \n",
       "2        (0,)       53    (1,)  (0,)  (1, 0, 0)         6     -1   \n",
       "3        (0,)      407    (1,)  (1,)  (0, 1, 0)         2     -1   \n",
       "4        (0,)     1770    (0,)  (1,)  (1, 0, 0)         2    188   \n",
       "...       ...      ...     ...   ...        ...       ...    ...   \n",
       "45206    (0,)        0    (1,)  (0,)  (0, 0, 1)         4     -1   \n",
       "45207    (0,)     2895    (1,)  (0,)  (1, 0, 0)         2    256   \n",
       "45208    (0,)      -32    (0,)  (0,)  (1, 0, 0)        12     -1   \n",
       "45209    (0,)      114    (1,)  (0,)  (0, 0, 1)         3     -1   \n",
       "45210    (0,)      827    (0,)  (0,)  (0, 0, 1)         1     -1   \n",
       "\n",
       "           poutcome   y  \n",
       "0      (0, 0, 0, 1)  no  \n",
       "1      (0, 0, 0, 1)  no  \n",
       "2      (0, 0, 0, 1)  no  \n",
       "3      (0, 0, 0, 1)  no  \n",
       "4      (1, 0, 0, 0)  no  \n",
       "...             ...  ..  \n",
       "45206  (0, 0, 0, 1)  no  \n",
       "45207  (1, 0, 0, 0)  no  \n",
       "45208  (0, 0, 0, 1)  no  \n",
       "45209  (0, 0, 0, 1)  no  \n",
       "45210  (0, 0, 0, 1)  no  \n",
       "\n",
       "[45211 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the DataFrame\n",
    "\n",
    "bank_dataframe = bank_dataframe.sample(frac=1).reset_index(drop=True)\n",
    "bank_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDCxC62VLwpF"
   },
   "source": [
    "#### Create the Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:32.702665Z",
     "start_time": "2021-03-15T02:01:32.487242Z"
    },
    "id": "58t232NWLwpF"
   },
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a Dataset\n",
    "\n",
    "bank_dataset = tf.data.Dataset.from_tensor_slices(dict(bank_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:33.313272Z",
     "start_time": "2021-03-15T02:01:33.307289Z"
    },
    "id": "wIam8gBSLwpH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'job': TensorSpec(shape=(12,), dtype=tf.int32, name=None),\n",
       " 'marital': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " 'education': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'default': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'balance': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'housing': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'loan': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'contact': TensorSpec(shape=(3,), dtype=tf.int32, name=None),\n",
       " 'campaign': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'pdays': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'poutcome': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'y': TensorSpec(shape=(), dtype=tf.string, name=None)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Dataset object\n",
    "\n",
    "bank_dataset.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0IxwSLpLwpN"
   },
   "source": [
    "#### Filter the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:35.023301Z",
     "start_time": "2021-03-15T02:01:35.005349Z"
    },
    "id": "s0m_HNo6LwpO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a person with marital status: b'married'\n"
     ]
    }
   ],
   "source": [
    "# First check that there are records in the dataset for non-married individuals\n",
    "\n",
    "def check_divorced():\n",
    "    bank_dataset_iterable = iter(bank_dataset)\n",
    "    for x in bank_dataset_iterable:\n",
    "        if x['marital'] != 'divorced':\n",
    "            print('Found a person with marital status: {}'.format(x['marital']))\n",
    "            return\n",
    "    print('No non-divorced people were found!')\n",
    "\n",
    "check_divorced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:56:41.199588Z",
     "start_time": "2021-03-15T02:56:41.158698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': <tf.Tensor: id=185087, shape=(), dtype=int32, numpy=36>, 'job': <tf.Tensor: id=185094, shape=(12,), dtype=int32, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])>, 'education': <tf.Tensor: id=185092, shape=(4,), dtype=int32, numpy=array([0, 0, 1, 0])>, 'default': <tf.Tensor: id=185091, shape=(1,), dtype=int32, numpy=array([0])>, 'balance': <tf.Tensor: id=185088, shape=(), dtype=int32, numpy=133>, 'housing': <tf.Tensor: id=185093, shape=(1,), dtype=int32, numpy=array([1])>, 'loan': <tf.Tensor: id=185095, shape=(1,), dtype=int32, numpy=array([0])>, 'contact': <tf.Tensor: id=185090, shape=(3,), dtype=int32, numpy=array([0, 0, 1])>, 'campaign': <tf.Tensor: id=185089, shape=(), dtype=int32, numpy=1>, 'pdays': <tf.Tensor: id=185096, shape=(), dtype=int32, numpy=-1>, 'poutcome': <tf.Tensor: id=185097, shape=(4,), dtype=int32, numpy=array([0, 0, 0, 1])>, 'y': <tf.Tensor: id=185098, shape=(), dtype=int32, numpy=0>}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'marital'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-219d3e3b7b0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbank_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'marital'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mb'divorced'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'marital'"
     ]
    }
   ],
   "source": [
    "for x in bank_dataset:\n",
    "    print(x)\n",
    "    print(tf.equal(x['marital'], tf.constant([b'divorced'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:36.010980Z",
     "start_time": "2021-03-15T02:01:35.747711Z"
    },
    "id": "1dpKPS8vLwpP"
   },
   "outputs": [],
   "source": [
    "# Filter the Dataset to retain only entries with a 'divorced' marital status\n",
    "\n",
    "# The input to the lambda function, x, is always referring to the DATASET object.\n",
    "\n",
    "bank_dataset = bank_dataset.filter(lambda x : tf.equal(x['marital'], tf.constant([b'divorced']))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T05:36:54.170950Z",
     "start_time": "2021-03-15T05:36:54.132079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "<MapDataset shapes: {age: (), job: (12,), education: (4,), default: (1,), balance: (), housing: (1,), loan: (1,), contact: (3,), campaign: (), pdays: (), poutcome: (4,), y: ()}, types: {age: tf.int32, job: tf.int32, education: tf.int32, default: tf.int32, balance: tf.int32, housing: tf.int32, loan: tf.int32, contact: tf.int32, campaign: tf.int32, pdays: tf.int32, poutcome: tf.int32, y: tf.int32}>\n"
     ]
    }
   ],
   "source": [
    "for x in bank_dataset.take(5):\n",
    "    print(len(x))\n",
    "    \n",
    "print(bank_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:40.577623Z",
     "start_time": "2021-03-15T02:01:36.577319Z"
    },
    "id": "xDqnULCjLwpR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No non-divorced people were found!\n"
     ]
    }
   ],
   "source": [
    "# Check the records in the dataset again\n",
    "\n",
    "check_divorced()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ljy2Ro9LwpS"
   },
   "source": [
    "#### Map a function over the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:42.355428Z",
     "start_time": "2021-03-15T02:01:42.352429Z"
    },
    "id": "qakJuUiNLwpS"
   },
   "outputs": [],
   "source": [
    "# Convert the label ('y') to an integer instead of 'yes' or 'no'\n",
    "\n",
    "# The input to the lambda function, x, is always referring to the DATASET object.\n",
    "\n",
    "def map_label(x):\n",
    "    \n",
    "    x['y'] = 0 if (x['y'] == tf.constant([b'no'], dtype = tf.string)) else 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:43.740183Z",
     "start_time": "2021-03-15T02:01:43.647431Z"
    },
    "id": "W1YcLNq7LwpT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'job': TensorSpec(shape=(12,), dtype=tf.int32, name=None),\n",
       " 'marital': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " 'education': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'default': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'balance': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'housing': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'loan': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'contact': TensorSpec(shape=(3,), dtype=tf.int32, name=None),\n",
       " 'campaign': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'pdays': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'poutcome': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'y': TensorSpec(shape=(), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Dataset object\n",
    "bank_dataset = bank_dataset.map(map_label)\n",
    "bank_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:45.004711Z",
     "start_time": "2021-03-15T02:01:44.976784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': <tf.Tensor: id=78217, shape=(), dtype=int32, numpy=36>, 'job': <tf.Tensor: id=78224, shape=(12,), dtype=int32, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])>, 'marital': <tf.Tensor: id=78226, shape=(), dtype=string, numpy=b'divorced'>, 'education': <tf.Tensor: id=78222, shape=(4,), dtype=int32, numpy=array([0, 0, 1, 0])>, 'default': <tf.Tensor: id=78221, shape=(1,), dtype=int32, numpy=array([0])>, 'balance': <tf.Tensor: id=78218, shape=(), dtype=int32, numpy=133>, 'housing': <tf.Tensor: id=78223, shape=(1,), dtype=int32, numpy=array([1])>, 'loan': <tf.Tensor: id=78225, shape=(1,), dtype=int32, numpy=array([0])>, 'contact': <tf.Tensor: id=78220, shape=(3,), dtype=int32, numpy=array([0, 0, 1])>, 'campaign': <tf.Tensor: id=78219, shape=(), dtype=int32, numpy=1>, 'pdays': <tf.Tensor: id=78227, shape=(), dtype=int32, numpy=-1>, 'poutcome': <tf.Tensor: id=78228, shape=(4,), dtype=int32, numpy=array([0, 0, 0, 1])>, 'y': <tf.Tensor: id=78229, shape=(), dtype=int32, numpy=0>}\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(bank_dataset.take(2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:47.004967Z",
     "start_time": "2021-03-15T02:01:46.939143Z"
    },
    "id": "6bSkBnzlLwpV"
   },
   "outputs": [],
   "source": [
    "# Remove the 'marital' column\n",
    "\n",
    "bank_dataset = bank_dataset.map(lambda x: {key:val for key,val in x.items() if key != 'marital'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:48.334511Z",
     "start_time": "2021-03-15T02:01:48.299605Z"
    },
    "id": "_lK3OmJ4LwpW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': <tf.Tensor: id=78265, shape=(), dtype=int32, numpy=36>, 'job': <tf.Tensor: id=78272, shape=(12,), dtype=int32, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])>, 'education': <tf.Tensor: id=78270, shape=(4,), dtype=int32, numpy=array([0, 0, 1, 0])>, 'default': <tf.Tensor: id=78269, shape=(1,), dtype=int32, numpy=array([0])>, 'balance': <tf.Tensor: id=78266, shape=(), dtype=int32, numpy=133>, 'housing': <tf.Tensor: id=78271, shape=(1,), dtype=int32, numpy=array([1])>, 'loan': <tf.Tensor: id=78273, shape=(1,), dtype=int32, numpy=array([0])>, 'contact': <tf.Tensor: id=78268, shape=(3,), dtype=int32, numpy=array([0, 0, 1])>, 'campaign': <tf.Tensor: id=78267, shape=(), dtype=int32, numpy=1>, 'pdays': <tf.Tensor: id=78274, shape=(), dtype=int32, numpy=-1>, 'poutcome': <tf.Tensor: id=78275, shape=(4,), dtype=int32, numpy=array([0, 0, 0, 1])>, 'y': <tf.Tensor: id=78276, shape=(), dtype=int32, numpy=0>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'job': TensorSpec(shape=(12,), dtype=tf.int32, name=None),\n",
       " 'education': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'default': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'balance': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'housing': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'loan': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'contact': TensorSpec(shape=(3,), dtype=tf.int32, name=None),\n",
       " 'campaign': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'pdays': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'poutcome': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'y': TensorSpec(shape=(), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Dataset object\n",
    "print(next(iter(bank_dataset.take(2))))\n",
    "bank_dataset.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5z_etyCZLwpZ"
   },
   "source": [
    "#### Create input and output data tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:50.791647Z",
     "start_time": "2021-03-15T02:01:50.786660Z"
    },
    "id": "6PStTjmKLwpZ"
   },
   "outputs": [],
   "source": [
    "# Create an input and output tuple for the dataset\n",
    "\n",
    "def map_feature_label(x):\n",
    "    features = [\n",
    "        [x['age']], [x['balance']], [x['campaign']], x['contact'], x['default'],\n",
    "        x['education'], x['housing'], x['job'], x['loan'], [x['pdays']], x['poutcome']\n",
    "    ]\n",
    "    return (tf.concat(features, axis=0), x['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:51.469777Z",
     "start_time": "2021-03-15T02:01:51.354086Z"
    },
    "id": "pKehf3i-Lwpc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((30,), ()), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map this function over the dataset\n",
    "\n",
    "bank_dataset.map(map_feature_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:52.662953Z",
     "start_time": "2021-03-15T02:01:52.630042Z"
    },
    "id": "yet0K8SjLwpd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': <tf.Tensor: id=78307, shape=(), dtype=int32, numpy=36>, 'job': <tf.Tensor: id=78314, shape=(12,), dtype=int32, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])>, 'education': <tf.Tensor: id=78312, shape=(4,), dtype=int32, numpy=array([0, 0, 1, 0])>, 'default': <tf.Tensor: id=78311, shape=(1,), dtype=int32, numpy=array([0])>, 'balance': <tf.Tensor: id=78308, shape=(), dtype=int32, numpy=133>, 'housing': <tf.Tensor: id=78313, shape=(1,), dtype=int32, numpy=array([1])>, 'loan': <tf.Tensor: id=78315, shape=(1,), dtype=int32, numpy=array([0])>, 'contact': <tf.Tensor: id=78310, shape=(3,), dtype=int32, numpy=array([0, 0, 1])>, 'campaign': <tf.Tensor: id=78309, shape=(), dtype=int32, numpy=1>, 'pdays': <tf.Tensor: id=78316, shape=(), dtype=int32, numpy=-1>, 'poutcome': <tf.Tensor: id=78317, shape=(4,), dtype=int32, numpy=array([0, 0, 0, 1])>, 'y': <tf.Tensor: id=78318, shape=(), dtype=int32, numpy=0>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'job': TensorSpec(shape=(12,), dtype=tf.int32, name=None),\n",
       " 'education': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'default': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'balance': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'housing': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'loan': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'contact': TensorSpec(shape=(3,), dtype=tf.int32, name=None),\n",
       " 'campaign': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'pdays': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'poutcome': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'y': TensorSpec(shape=(), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Dataset object\n",
    "print(next(iter(bank_dataset.take(2))))\n",
    "bank_dataset.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7rFrXSkLwpf"
   },
   "source": [
    "#### Split into a training and a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:58.467157Z",
     "start_time": "2021-03-15T02:01:54.608475Z"
    },
    "id": "u16htz4qLwpg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5207\n"
     ]
    }
   ],
   "source": [
    "# Determine the length of the Dataset\n",
    "\n",
    "dataset_length = 0\n",
    "for _ in bank_dataset:\n",
    "    dataset_length += 1\n",
    "print(dataset_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:01:59.153866Z",
     "start_time": "2021-03-15T02:01:59.149877Z"
    },
    "id": "AFo3xsyQLwph"
   },
   "outputs": [],
   "source": [
    "# Make training and validation sets from the dataset\n",
    "\n",
    "training_elements = int(dataset_length * 0.7)\n",
    "train_dataset = bank_dataset.take(training_elements)\n",
    "validation_dataset = bank_dataset.skip(training_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:02:02.185117Z",
     "start_time": "2021-03-15T02:01:59.640466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3644\n"
     ]
    }
   ],
   "source": [
    "train_dataset_length = 0\n",
    "for _ in train_dataset:\n",
    "    train_dataset_length += 1\n",
    "print(train_dataset_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:02:02.220036Z",
     "start_time": "2021-03-15T02:02:02.186114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': <tf.Tensor: id=184552, shape=(), dtype=int32, numpy=36>, 'job': <tf.Tensor: id=184559, shape=(12,), dtype=int32, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])>, 'education': <tf.Tensor: id=184557, shape=(4,), dtype=int32, numpy=array([0, 0, 1, 0])>, 'default': <tf.Tensor: id=184556, shape=(1,), dtype=int32, numpy=array([0])>, 'balance': <tf.Tensor: id=184553, shape=(), dtype=int32, numpy=133>, 'housing': <tf.Tensor: id=184558, shape=(1,), dtype=int32, numpy=array([1])>, 'loan': <tf.Tensor: id=184560, shape=(1,), dtype=int32, numpy=array([0])>, 'contact': <tf.Tensor: id=184555, shape=(3,), dtype=int32, numpy=array([0, 0, 1])>, 'campaign': <tf.Tensor: id=184554, shape=(), dtype=int32, numpy=1>, 'pdays': <tf.Tensor: id=184561, shape=(), dtype=int32, numpy=-1>, 'poutcome': <tf.Tensor: id=184562, shape=(4,), dtype=int32, numpy=array([0, 0, 0, 1])>, 'y': <tf.Tensor: id=184563, shape=(), dtype=int32, numpy=0>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'job': TensorSpec(shape=(12,), dtype=tf.int32, name=None),\n",
       " 'education': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'default': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'balance': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'housing': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'loan': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'contact': TensorSpec(shape=(3,), dtype=tf.int32, name=None),\n",
       " 'campaign': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'pdays': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'poutcome': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'y': TensorSpec(shape=(), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Dataset object\n",
    "print(next(iter(bank_dataset.take(2))))\n",
    "bank_dataset.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waZerBcdLwpj"
   },
   "source": [
    "#### Build a classification model\n",
    "\n",
    "Now let's build a model to classify the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:02:23.820811Z",
     "start_time": "2021-03-15T02:02:23.555522Z"
    },
    "id": "AMFNjG7PLwpj"
   },
   "outputs": [],
   "source": [
    "# Build a classifier model\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, BatchNormalization\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(30,)))\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:02:27.804843Z",
     "start_time": "2021-03-15T02:02:27.758966Z"
    },
    "id": "4Ov8EijXLwpk"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:02:28.462577Z",
     "start_time": "2021-03-15T02:02:28.455627Z"
    },
    "id": "VtbN-lMbLwpl",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 400)               12400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 400)               1600      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 400)               1600      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 176,521\n",
      "Trainable params: 174,861\n",
      "Non-trainable params: 1,660\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show the model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6euItJ8bLwpn"
   },
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:02:33.058013Z",
     "start_time": "2021-03-15T02:02:33.052054Z"
    },
    "id": "O0-gu3b4Lwpo"
   },
   "outputs": [],
   "source": [
    "# Create batched training and validation datasets\n",
    "\n",
    "train_dataset = train_dataset.shuffle(1000)\n",
    "train_dataset = train_dataset.batch(20, drop_remainder = True)\n",
    "train_dataset = train_dataset.repeat()\n",
    "validation_dataset = validation_dataset.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:23:52.673094Z",
     "start_time": "2021-03-15T01:23:52.641114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': <tf.Tensor: id=326232, shape=(), dtype=int32, numpy=36>, 'job': <tf.Tensor: id=326239, shape=(12,), dtype=int32, numpy=array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])>, 'education': <tf.Tensor: id=326237, shape=(4,), dtype=int32, numpy=array([0, 0, 1, 0])>, 'default': <tf.Tensor: id=326236, shape=(1,), dtype=int32, numpy=array([0])>, 'balance': <tf.Tensor: id=326233, shape=(), dtype=int32, numpy=7821>, 'housing': <tf.Tensor: id=326238, shape=(1,), dtype=int32, numpy=array([0])>, 'loan': <tf.Tensor: id=326240, shape=(1,), dtype=int32, numpy=array([0])>, 'contact': <tf.Tensor: id=326235, shape=(3,), dtype=int32, numpy=array([0, 0, 1])>, 'campaign': <tf.Tensor: id=326234, shape=(), dtype=int32, numpy=1>, 'pdays': <tf.Tensor: id=326241, shape=(), dtype=int32, numpy=-1>, 'poutcome': <tf.Tensor: id=326242, shape=(4,), dtype=int32, numpy=array([0, 0, 0, 1])>, 'y': <tf.Tensor: id=326243, shape=(), dtype=int32, numpy=0>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'job': TensorSpec(shape=(12,), dtype=tf.int32, name=None),\n",
       " 'education': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'default': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'balance': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'housing': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'loan': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'contact': TensorSpec(shape=(3,), dtype=tf.int32, name=None),\n",
       " 'campaign': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'pdays': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'poutcome': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'y': TensorSpec(shape=(), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(next(iter(train_dataset.take(2))))\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:34:20.979597Z",
     "start_time": "2021-03-15T01:34:20.974611Z"
    },
    "id": "tSc4I6lhLwpp"
   },
   "outputs": [],
   "source": [
    "# Shuffle the training data\n",
    "\n",
    "train_dataset = train_dataset.shuffle(1000)\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T01:35:41.533817Z",
     "start_time": "2021-03-15T01:35:41.529747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.RepeatDataset"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T02:04:59.972260Z",
     "start_time": "2021-03-15T02:04:59.919403Z"
    },
    "id": "BBzjSPpLLwpr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 182 steps\n",
      "\r",
      "  1/182 [..............................] - ETA: 4s"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'input_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-d2eb817d34eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset_length\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    492\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1820\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1822\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1823\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2150\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    913\u001b[0m                                           converted_func)\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[1;34m(input_iterator)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;34m\"\"\"A single step of the distributed execution across replicas.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     x, y, sample_weights = _prepare_feed_values(\n\u001b[1;32m---> 66\u001b[1;33m         model, input_iterator, mode)\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[1;31m# Call `Model.{train,test,predict}_on_batch` on every replica passing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# PerReplicas as arguments.  On every replica inside this call, each\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36m_prepare_feed_values\u001b[1;34m(model, inputs, mode)\u001b[0m\n\u001b[0;32m    116\u001b[0m   \u001b[1;31m# correct order.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelInputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    116\u001b[0m   \u001b[1;31m# correct order.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelInputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'input_1'"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_dataset, steps_per_epoch = train_dataset_length//20, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKUL_6uvLwps"
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "slDi0LNSLwlk",
    "1tPbAdRYLwmH",
    "YLOK8GMOLwmP",
    "KA-VnvRpLwmW",
    "-djfT1vDLwma",
    "wxB-r6_sLwmd",
    "eASEXb7uLwml",
    "CndbEe9-Lwmw",
    "2PTkNo-uLwm-",
    "tyi9F1cRLwnF",
    "KUfxD0WHLwnU",
    "8lDJvPvfLwnd",
    "IuICkLdgLwnv",
    "EdlrTTxkLwn1",
    "LoxWasQKLwn5",
    "zS5yD7TaLwn7",
    "vqqV3Ox9LwoA",
    "5d8X74-yLwoL",
    "agL_w4bhLwoU",
    "EgdUwwomLwom",
    "FJWNhXxMLwov",
    "WDGZ4VF-LwpC",
    "PDCxC62VLwpF",
    "B0IxwSLpLwpN",
    "8Ljy2Ro9LwpS",
    "5z_etyCZLwpZ",
    "H7rFrXSkLwpf",
    "waZerBcdLwpj",
    "6euItJ8bLwpn"
   ],
   "name": "Coding Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
